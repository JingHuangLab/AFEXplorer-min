Script started on Thu 07 Dec 2023 06:30:18 PM CST
ksongzl@zimei:~/projects/0.pycospath\(base) [songzl@node38 0.pycospath]$ module load mathlib/u[Kvu[Kc[K[Kcud
mathlib/cuda                     mathlib/cuda/10.1.168_418.67     mathlib/cuda/11.7.1_515.65.01    mathlib/cuda/8.0.61_375.26       mathlib/cuda/9.1.85_387.26       mathlib/cudnn                    mathlib/cudnn/7.6.5.32+cuda10.1  mathlib/cudnn/8.5.0.96+cuda11.x  
mathlib/cuda/10.0.130_410.48     mathlib/cuda/11.2.2_460.32.03    mathlib/cuda/7.5.18              mathlib/cuda/9.0.176_384.81      mathlib/cuda/9.2.148_396.37      mathlib/cudnn/7.6.5.32+cuda10.0  mathlib/cudnn/8.1.1.33+cuda11.2  
(base) [songzl@node38 0.pycospath]$ module load mathlib/cuda
mathlib/cuda                   mathlib/cuda/10.1.168_418.67   mathlib/cuda/11.7.1_515.65.01  mathlib/cuda/8.0.61_375.26     mathlib/cuda/9.1.85_387.26     
mathlib/cuda/10.0.130_410.48   mathlib/cuda/11.2.2_460.32.03  mathlib/cuda/7.5.18            mathlib/cuda/9.0.176_384.81    mathlib/cuda/9.2.148_396.37    
(base) [songzl@node38 0.pycospath]$ module load mathlib/cuda
mathlib/cuda                   mathlib/cuda/10.1.168_418.67   mathlib/cuda/11.7.1_515.65.01  mathlib/cuda/8.0.61_375.26     mathlib/cuda/9.1.85_387.26     
mathlib/cuda/10.0.130_410.48   mathlib/cuda/11.2.2_460.32.03  mathlib/cuda/7.5.18            mathlib/cuda/9.0.176_384.81    mathlib/cuda/9.2.148_396.37    
(base) [songzl@node38 0.pycospath]$ module load mathlib/cuda11.[K[K[K2[K11[K[K/11.2.2_460.32.03 
ksongzl@zimei:~/projects/0.pycospath\(base) [songzl@node38 0.pycospath]$ conda activate afex
ksongzl@zimei:~/projects/0.pycospath\(afex) [songzl@node38 0.pycospath]$ p[Kb[Kcd ../2.afexplorer/
ksongzl@zimei:~/projects/2.afexplorer\(afex) [songzl@node38 2.afexplorer]$ ls
0_af_feat.sh  1_run_afex.sh  [0m[38;5;27mafexplore[0m  [38;5;27mdata[0m  LICENSE  log  nclust_512.log  README.md
ksongzl@zimei:~/projects/2.afexplorer\(afex) [songzl@node38 2.afexplorer]$ vash [K[K[K[K[Kbash 1_run_afex.sh 
/home/songzl/software/miniconda3/envs/afex/lib/python3.9/site-packages/absl/flags/_validators.py:233: UserWarning: Flag --nsteps has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  mark_flag_as_required(flag_name, flag_values)
/home/songzl/software/miniconda3/envs/afex/lib/python3.9/site-packages/absl/flags/_validators.py:233: UserWarning: Flag --nclust has a non-None default value; therefore, mark_flag_as_required will pass even if flag is not specified in the command line!
  mark_flag_as_required(flag_name, flag_values)
I1207 18:30:56.416028 47719857172160 xla_bridge.py:353] Unable to initialize backend 'tpu_driver': NOT_FOUND: Unable to find driver in registry given worker: 
I1207 18:30:59.254348 47719857172160 xla_bridge.py:353] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA Host Interpreter
I1207 18:30:59.254768 47719857172160 xla_bridge.py:353] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'
I1207 18:30:59.254861 47719857172160 xla_bridge.py:353] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.
AFEX started.
Runing step 0
2023-12-07 18:31:29.209462: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 1s:

  reduce.637 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2023-12-07 18:31:31.130412: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2.921044176s
Constant folding an instruction is taking > 1s:

  reduce.637 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2023-12-07 18:31:33.175482: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:65] Constant folding an instruction is taking > 2s:

  reduce.50 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
2023-12-07 18:31:34.158252: E external/org_tensorflow/tensorflow/compiler/xla/service/slow_operation_alarm.cc:133] The operation took 2.982841732s
Constant folding an instruction is taking > 2s:

  reduce.50 (displaying the full instruction incurs a runtime overhead. Raise your logging level to 4 or above).

This isn't necessarily a bug; constant-folding is inherently a trade-off between compilation time and speed at runtime.  XLA has some guards that attempt to keep constant folding from taking too long, but fundamentally you'll always be able to come up with an input program that takes a long time.

If you'd like to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.
Done Step 0: plddt_loss: 0.09981095790863037; cv_loss: 6998.57373046875
Runing step 1
Done Step 1: plddt_loss: 0.09536093473434448; cv_loss: 5474.15966796875
Runing step 2
Done Step 2: plddt_loss: 0.08711546659469604; cv_loss: 3129.865966796875
Runing step 3
Done Step 3: plddt_loss: 0.08425343036651611; cv_loss: 1840.464111328125
Runing step 4
Done Step 4: plddt_loss: 0.08791595697402954; cv_loss: 703.0322265625
Runing step 5
Done Step 5: plddt_loss: 0.0914720892906189; cv_loss: 326.9957275390625
Runing step 6
Done Step 6: plddt_loss: 0.10922569036483765; cv_loss: 89.11739349365234
Runing step 7
Done Step 7: plddt_loss: 0.12274545431137085; cv_loss: 20.84691047668457
Runing step 8
Done Step 8: plddt_loss: 0.134160578250885; cv_loss: 9.90185260772705
Runing step 9
Done Step 9: plddt_loss: 0.13598889112472534; cv_loss: 0.3085421323776245
ksongzl@zimei:~/projects/2.afexplorer\(afex) [songzl@node38 2.afexplorer]$ bash 1_run_afex.sh [Ke[Kalias exit="exit"
ksongzl@zimei:~/projects/2.afexplorer\(afex) [songzl@node38 2.afexplorer]$ exit
exit

Script done on Thu 07 Dec 2023 06:46:35 PM CST
